{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jndmk1TVPUyp"
   },
   "source": [
    "# CIFAR10 Training and quantization\n",
    "\n",
    "Project inspired by this [kaggle competition](https://www.kaggle.com/ektasharma/simple-cifar10-cnn-keras-code-with-88-accuracy#A-Simple-Keras-CNN-trained-on-CIFAR-10-dataset-with-over-88%-accuracy-(Without-Data-Augmentation). In this colab you will be driven through the training of a CNN for CIFAR10 classification task. The model is then exported for inference with tflite and quantized, prepared for the *GAPflow*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cj6DcUxZAOse"
   },
   "source": [
    "### Used python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "KNb0mejGAHCV"
   },
   "outputs": [],
   "source": [
    "from keras_model import *\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras import datasets\n",
    "from keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import os\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ynH1CrIeC7l9",
    "outputId": "27185c8d-5330-4655-8353-8ab49cc6a76d"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__, tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DTon9QahBjz3"
   },
   "source": [
    "# Reading the CIFAR-10 dataset from Keras datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Y73NtaTwAJGn",
    "outputId": "26ce625b-21aa-4153-ebf2-1103585b6fe4"
   },
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "train_images, train_labels = train_images[:10000], train_labels[:10000]\n",
    "test_images, test_labels = test_images[:1000], test_labels[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qnpbZeX8Ab08",
    "outputId": "afca2f22-80e7-4153-ca25-7b8bef0ac7e9"
   },
   "outputs": [],
   "source": [
    "# Checking the number of rows (records) and columns (features)\n",
    "print(train_images.shape)\n",
    "print(train_labels.shape)\n",
    "print(test_images.shape)\n",
    "print(test_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uuLdAMSkBsQL",
    "outputId": "26fcf4ee-1c97-46b2-8663-f9b32151da1c"
   },
   "outputs": [],
   "source": [
    "# Checking the number of unique classes \n",
    "print(np.unique(train_labels))\n",
    "print(np.unique(test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "0YoOBr90BtWH"
   },
   "outputs": [],
   "source": [
    "# Creating a list of all the class labels\n",
    "class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
    "               'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 589
    },
    "id": "JwRU0I-sBuh3",
    "outputId": "45c3aa84-2f34-4c06-ef18-b9e3c6ab4c0f"
   },
   "outputs": [],
   "source": [
    "# Visualizing some of the images from the training dataset\n",
    "plt.figure(figsize=[10,10])\n",
    "for i in range (25):    # for first 25 images\n",
    "    plt.subplot(5, 5, i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(train_images[i], cmap=plt.cm.binary)\n",
    "    plt.xlabel(class_names[train_labels[i][0]])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mA408CROB8m3"
   },
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Convert input [0:255] to [-1:1] float\n",
    "\n",
    "Convert labels to one hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "2HS36TpJBvrK"
   },
   "outputs": [],
   "source": [
    "# Converting the pixels data to float type\n",
    "train_images = train_images.astype('float32')\n",
    "test_images = test_images.astype('float32')\n",
    "\n",
    "# Standardizing (255 is the total number of pixels an image can have)\n",
    "train_images = (train_images / 128) - 1.0\n",
    "test_images = (test_images / 128) - 1.0\n",
    "\n",
    "# One hot encoding the target class (labels)\n",
    "num_classes = 10\n",
    "train_labels = to_categorical(train_labels, num_classes)\n",
    "test_labels = to_categorical(test_labels, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Uk9v8V2gCFXF",
    "outputId": "2568277e-f3cb-4eec-ce03-6fc7ad5bd197"
   },
   "outputs": [],
   "source": [
    "MODEL_VERSION = 4\n",
    "\n",
    "if MODEL_VERSION == 1:\n",
    "    model = model_v1()\n",
    "    model_name = \"v1\"\n",
    "elif MODEL_VERSION == 2:\n",
    "    model = model_v2()\n",
    "    model_name = \"v2\"\n",
    "elif MODEL_VERSION == 3:\n",
    "    model = model_v3()\n",
    "    model_name = \"v3\"\n",
    "elif MODEL_VERSION == 4:\n",
    "    model = model_v4()\n",
    "    model_name = \"v4\"\n",
    "# elif MODEL_VERSION == 5:\n",
    "#     model = model_v5()\n",
    "#     model_name = \"v5\"\n",
    "\n",
    "# Checking the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mgrXAkCkCRzL"
   },
   "source": [
    "# Compile and Train the model (or load the pretrained one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "PZL5RClrCN1h"
   },
   "outputs": [],
   "source": [
    "#checkpoint_path = \"gdrive/MyDrive/cifar10/saved_model/my_model\"\n",
    "checkpoint_path = f\"./checkpoints/saved_model_{model_name}/\"\n",
    "train_again = False\n",
    "\n",
    "if os.path.exists(checkpoint_path) and not train_again:\n",
    "    model = tf.keras.models.load_model(checkpoint_path)\n",
    "    history = None\n",
    "else:\n",
    "    model.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "    history = model.fit(train_images, train_labels, batch_size=128, epochs=10, # Add more epochs to get better results\n",
    "                      validation_data=(test_images, test_labels))\n",
    "    model.save(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making the Predictions\n",
    "pred = model.predict(test_images)\n",
    "accuracy = 100 * np.sum(np.argmax(pred, 1) == np.argmax(test_labels, 1)) / len(test_labels)\n",
    "print(f\"Trained model Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfryV1T7EhYG"
   },
   "source": [
    "# Visualize training results\n",
    "\n",
    "Only available if you have trained the model in this session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kxQKwWtEEjIP"
   },
   "outputs": [],
   "source": [
    "if history:\n",
    "    # Loss curve\n",
    "    plt.figure(figsize=[6,4])\n",
    "    plt.plot(history.history['loss'], 'black', linewidth=2.0)\n",
    "    plt.plot(history.history['val_loss'], 'green', linewidth=2.0)\n",
    "    plt.legend(['Training Loss', 'Validation Loss'], fontsize=14)\n",
    "    plt.xlabel('Epochs', fontsize=10)\n",
    "    plt.ylabel('Loss', fontsize=10)\n",
    "    plt.title('Loss Curves', fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7Ox9LUAfEqR8"
   },
   "outputs": [],
   "source": [
    "if history:\n",
    "    # Accuracy curve\n",
    "    plt.figure(figsize=[6,4])\n",
    "    plt.plot(history.history['accuracy'], 'black', linewidth=2.0)\n",
    "    plt.plot(history.history['val_accuracy'], 'blue', linewidth=2.0)\n",
    "    plt.legend(['Training Accuracy', 'Validation Accuracy'], fontsize=14)\n",
    "    plt.xlabel('Epochs', fontsize=10)\n",
    "    plt.ylabel('Accuracy', fontsize=10)\n",
    "    plt.title('Accuracy Curves', fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDGTyZ-SEwQD"
   },
   "source": [
    "# See the model at work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 830
    },
    "id": "UaWOvQi4EycM",
    "outputId": "7d2b2819-32e0-4d5d-a0ce-1a68cf2b31f1"
   },
   "outputs": [],
   "source": [
    "# Plotting the Actual vs. Predicted results\n",
    "# Converting the predictions into label index \n",
    "pred_classes = np.argmax(pred, axis=1)\n",
    "\n",
    "fig, axes = plt.subplots(5, 5, figsize=(15,15))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i in np.arange(0, 25):\n",
    "    axes[i].imshow((128*(test_images[i]+1)).astype(np.uint8))\n",
    "    axes[i].set_title(f\"True: {class_names[np.argmax(test_labels[i])]}\\nPredict: {class_names[pred_classes[i]]}\", color=\"r\" if class_names[np.argmax(test_labels[i])]!=class_names[pred_classes[i]] else \"b\")\n",
    "    axes[i].axis('off')\n",
    "    plt.subplots_adjust(wspace=1)\n",
    "    img = Image.fromarray(np.uint8(128*(test_images[i]+1)))\n",
    "    img.save(f\"samples/cifar_test_{i}_{np.argmax(test_labels[i])}.ppm\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHnm2AaEFFLE"
   },
   "source": [
    "# Convert to tflite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "UhLXJ5mCFJ8W"
   },
   "outputs": [],
   "source": [
    "# Helper function to run inference on a TFLite model\n",
    "def test_tflite_model(tflite_file, test_images, test_labels):\n",
    "    # Initialize the interpreter\n",
    "    interpreter = tf.lite.Interpreter(model_path=str(tflite_file))\n",
    "    interpreter.allocate_tensors()\n",
    "\n",
    "    input_details = interpreter.get_input_details()[0]\n",
    "    output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "    predictions = np.zeros((len(test_images),), dtype=int)\n",
    "    for i, (test_image, test_label) in enumerate(tqdm(zip(test_images, test_labels), total=len(test_labels))):\n",
    "        # Check if the input type is quantized, then rescale input data to uint8\n",
    "        if input_details['dtype'] == np.uint8:\n",
    "            input_scale, input_zero_point = input_details[\"quantization\"]\n",
    "            test_image = test_image / input_scale + input_zero_point\n",
    "\n",
    "        test_image = np.expand_dims(test_image, axis=0).astype(input_details[\"dtype\"])\n",
    "        interpreter.set_tensor(input_details[\"index\"], test_image)\n",
    "        interpreter.invoke()\n",
    "        output = interpreter.get_tensor(output_details[\"index\"])[0]\n",
    "\n",
    "        predictions[i] = output.argmax()\n",
    "\n",
    "    test_labels_not_one_hot = np.argmax(test_labels, 1)\n",
    "    accuracy = (np.sum(test_labels_not_one_hot == predictions) * 100) / len(test_images)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_model_file = pathlib.Path(f\"{checkpoint_path}/cifar10_model_{model_name}_fp32.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "s_w0Bbs9FGjv",
    "outputId": "fcee918c-1e4b-45bd-e5ef-385c2ac6f226"
   },
   "outputs": [],
   "source": [
    "# Converting a tf.Keras model to a TensorFlow Lite model.\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the unquantized/float model:\n",
    "tflite_model_file.write_bytes(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kRlsyupjGFaa",
    "outputId": "0991c086-4d83-4088-a9cf-72bb90f37f26"
   },
   "outputs": [],
   "source": [
    "fp32_accuracy = test_tflite_model(tflite_model_file, test_images, test_labels)\n",
    "print(f\"\\nFloat model accuracy: {fp32_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-VqlDQv9HlJP"
   },
   "source": [
    "## Quantize to int8\n",
    "\n",
    "We use post training integer quantization to quantize the model (https://www.tensorflow.org/lite/performance/post_training_integer_quant).\n",
    "\n",
    "Weights are quantized directly from their values (they are constants), activations on the other hand depend on the input data. Hence we need to provide a calibration dataset to the quantizer so that it can run inference on it and collect the statistics of each layer in order to quantize the values in those ranges, i.e. Layer1 -> [-3.0, 6.0], Layer2 -> [-1.0, 2.5], ...\n",
    "\n",
    "As calibration dataset we need representative data of our use case. They cannot be the testing set, we are \"learning\" the statistics so using test dataset would be cheating. A subset of the training is tipycally used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v4Vf9wK0GqZ0",
    "outputId": "e3c201f1-b413-4dea-e3e5-7c6bce8df55a"
   },
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter.inference_input_type = tf.uint8\n",
    "converter.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_quant = converter.convert()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tflite_quant_model_file = pathlib.Path(f\"{checkpoint_path}/cifar10_model_{model_name}_uint8.tflite\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the unquantized/float model:\n",
    "tflite_quant_model_file.write_bytes(tflite_model_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qm4RO-GIHCdW",
    "outputId": "6219c701-5212-463b-bb9f-8ed8839c0cd1"
   },
   "outputs": [],
   "source": [
    "quant_accuracy = test_tflite_model(tflite_quant_model_file, test_images[:1000], test_labels[:1000])\n",
    "print(f\"Quantized model accuracy: {quant_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantize to INT8 using QAT\n",
    "\n",
    "After performing post-training quantization, we might notice an accuracy drop between the FP32 and INT8 networks. As the weights are kept constant during PTQ and the activations' range is analysed only with respect to the input (calibration) data, such a quantization strategy, albeit quick, can render a model inefficient.\n",
    "\n",
    "Quantization-aware training (QAT) updates the model's weights whilst reducing the bitwidth. A comprehensive guide on TensorFlow-based QAT is available [here](https://www.tensorflow.org/model_optimization/guide/quantization/training_comprehensive_guide)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_model_optimization as tfmot\n",
    "# Clone the trained TensorFlow model\n",
    "\n",
    "tf_model_qat = tfmot.quantization.keras.quantize_model(model)\n",
    "\n",
    "# We need to compile again the model\n",
    "tf_model_qat.compile(optimizer='adam', loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "tf_model_qat.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finetune the fake-quantized model on a subset of the training data\n",
    "\n",
    "checkpoint_path = f\"./checkpoints/saved_model_qat_{model_name}/\"\n",
    "\n",
    "history = tf_model_qat.fit(train_images, train_labels, batch_size=64, epochs=1, # Add more epochs to get better results\n",
    "                  validation_data=(test_images, test_labels))\n",
    "tf_model_qat.save(checkpoint_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the QAT model\n",
    "\n",
    "pred = tf_model_qat.predict(test_images)\n",
    "accuracy = 100 * np.sum(np.argmax(pred, 1) == np.argmax(test_labels, 1)) / len(test_labels)\n",
    "print(f\"Trained model Accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quantize and save the model\n",
    "\n",
    "def representative_data_gen():\n",
    "  for input_value in tf.data.Dataset.from_tensor_slices(train_images).batch(1).take(100):\n",
    "    yield [input_value]\n",
    "\n",
    "converter_qat = tf.lite.TFLiteConverter.from_keras_model(tf_model_qat)\n",
    "converter_qat.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter_qat.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "converter_qat.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "converter_qat.inference_input_type = tf.uint8\n",
    "converter_qat.inference_output_type = tf.uint8\n",
    "\n",
    "tflite_model_qat_quant = converter_qat.convert()\n",
    "\n",
    "tflite_quant_qat_model_file = pathlib.Path(f\"{checkpoint_path}/model/cifar10_qat_{model_name}_uint8.tflite\")\n",
    "tflite_quant_qat_model_file.write_bytes(tflite_model_qat_quant)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the QAT model\n",
    "quant_qat_accuracy = test_tflite_model(tflite_quant_qat_model_file, test_images, test_labels)\n",
    "print(f\"Quantized model accuracy: {quant_qat_accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did the accuracy increase compared to the PTQ solution? By how much?\n",
    "<br>\n",
    "Is this due to the benefits of QAT? How can you tell?"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CIFAR10_TFLITE.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "nntool",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
